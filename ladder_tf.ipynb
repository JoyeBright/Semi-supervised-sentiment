{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ladder_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPN7bvslV4R9Q81e9XcRYZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoyeBright/Semi-supervised-sentiment/blob/ImageLadder/ladder_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxVe3Mf9XDfD",
        "colab_type": "text"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOz8gBNFi06d",
        "colab_type": "code",
        "outputId": "46453f54-b753-47e7-e094-fdd78cc083f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzQH4vZ3XZiy",
        "colab_type": "code",
        "outputId": "2421563f-9040-4149-ef10-6335b9331b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "%run /content/ladder_input.ipynb\n",
        "# Downgrade since colab installed tensorflow version 2.2.0 and it does not support placeholder as well\n",
        "!pip install tensorflow==1.1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.1 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.1) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.1) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.1) (1.18.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.1) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.1) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.1) (46.3.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:455: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:456: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:457: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF9Emi4JmUjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_sizes = [784, 1000, 500, 250, 250, 250, 10]\n",
        "\n",
        "L = len(layer_sizes) - 1  # number of layers\n",
        "\n",
        "num_examples = 60000 # a training set of 60,000 examples\n",
        "num_epochs = 150\n",
        "num_labeled = 100\n",
        "\n",
        "started_learning_rate = 0.02\n",
        "\n",
        "decay_after = 15\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "num_iter = (num_examples/batch_size) * num_epochs\n",
        "\n",
        "inputs = tf.placeholder(tf.float32, shape=(None, layer_sizes[0]))\n",
        "outputs = tf.placeholder(tf.float32)\n",
        "\n",
        "def bi(inits, size, name):\n",
        "    return tf.Variable(inits * tf.ones([size]), name=name)\n",
        "\n",
        "def wi(shape, name):\n",
        "    return tf.Variable(tf.random_normal(shape, name=name)) / math.sqrt(shape[0])\n",
        "\n",
        "shapes = zip(layer_sizes[:-1], layer_sizes[1:])  # shapes of linear layers\n",
        "\n",
        "weights = {'W': [wi(s, \"W\") for s in shapes],  # Encoder weights\n",
        "                 'V': [wi(s[::-1], \"V\") for s in shapes],  # Decoder weights\n",
        "                 # batch normalization parameter to shift the normalized value\n",
        "                 'beta': [bi(0.0, layer_sizes[l+1], \"beta\") for l in range(L)],\n",
        "                 # batch normalization parameter to scale the normalized value\n",
        "                 'gamma': [bi(1.0, layer_sizes[l+1], \"beta\") for l in range(L)]}\n",
        "\n",
        "noise_std = 0.3  # scaling factor for noise used in corrupted encoder\n",
        "\n",
        "# hyperparameters that denote the importance of each layer\n",
        "denoising_cost = [1000.0, 10.0, 0.10, 0.10, 0.10, 0.10, 0.10]\n",
        "\n",
        "join = lambda l, u: tf.concat([l, u], 0)\n",
        "labeled = lambda x: tf.slice(x, [0, 0], [batch_size, -1]) if x is not None else x\n",
        "unlabeled = lambda x: tf.slice(x, [batch_size, 0], [-1, -1]) if x is not None else x\n",
        "split_lu = lambda x: (labeled(x), unlabeled(x))\n",
        "\n",
        "training = tf.placeholder(tf.bool)\n",
        "\n",
        "ewma = tf.train.ExponentialMovingAverage(decay=0.99)  # to calculate the moving averages of mean and variance\n",
        "bn_assigns = []  # this list stores the updates to be made to average mean and variance\n",
        "\n",
        "\n",
        "def batch_normalization(batch, mean=None, var=None):\n",
        "    if mean is None or var is None:\n",
        "        mean, var = tf.nn.moments(batch, axes=[0])\n",
        "    return (batch - mean) / tf.sqrt(var + tf.constant(1e-10))\n",
        "\n",
        "# average mean and variance of all layers\n",
        "running_mean = [tf.Variable(tf.constant(0.0, shape=[l]), trainable=False) for l in layer_sizes[1:]]\n",
        "running_var = [tf.Variable(tf.constant(1.0, shape=[l]), trainable=False) for l in layer_sizes[1:]]\n",
        "\n",
        "\n",
        "def update_batch_normalization(batch, l):\n",
        "    \"batch normalize + update average mean and variance of layer l\"\n",
        "    mean, var = tf.nn.moments(batch, axes=[0])\n",
        "    assign_mean = running_mean[l-1].assign(mean)\n",
        "    assign_var = running_var[l-1].assign(var)\n",
        "    bn_assigns.append(ewma.apply([running_mean[l-1], running_var[l-1]]))\n",
        "    with tf.control_dependencies([assign_mean, assign_var]):\n",
        "        return (batch - mean) / tf.sqrt(var + 1e-10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}